{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料處理常用函示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 空值處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# 檢查 DataFrame 空缺值的狀態\n",
    "def na_check(df_data):\n",
    "    data_na = (df_data.isnull().sum() / len(df_data)) * 100\n",
    "    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "    display(missing_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore NA, 計算百分位\n",
    "def get_percentile(nums,series):\n",
    "    return [np.percentile(series, q = i) for i in nums]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徵工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#均值編碼\n",
    "def perform_mean_encoding(f1,f2,df):\n",
    "    mean_df = df.groupby([f1])[f2].mean().reset_index()\n",
    "    mean_df.columns = [f1, f'{f1}_mean']\n",
    "    df = pd.merge(df, mean_df, on=f1, how='left')\n",
    "    return df.drop([f1] , axis=1)\n",
    "\n",
    "#眾數編碼\n",
    "def perform_mode_encoding(f1,f2,df):\n",
    "    mode_df = df.groupby([f1])[f2].apply(lambda x: x.mode()[0]).reset_index()\n",
    "    mode_df.columns = [f1, f'{f1}_mode']\n",
    "    df = pd.merge(df, mode_df, on=f1, how='left')\n",
    "    return df.drop([f1] , axis=1)\n",
    "\n",
    "#中位數編碼\n",
    "def perform_median_encoding(f1,f2,df):\n",
    "    median_df = df.groupby([f1])[f2].median().reset_index()\n",
    "    mode_df.columns = [f1, f'{f1}_mode']\n",
    "    df = pd.merge(df, mode_df, on=f1, how='left')\n",
    "    return df.drop([f1] , axis=1)\n",
    "\n",
    "#test\n",
    "df = pd.DataFrame({\"f1\":[\"Jerry\",\"Jerry\",\"Jerry\"],\"f2\":[\"dog\",\"cat\",\"cat\"]})\n",
    "perform_mode_encoding(\"f1\",\"f2\",df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徵重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, datasets\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(x,y):\n",
    "    # 梯度提升樹擬合後, 將結果依照重要性由高到低排序\n",
    "    estimator = GradientBoostingRegressor()\n",
    "    estimator.fit(x, y)\n",
    "    # estimator.feature_importances_ 就是模型的特徵重要性, 這邊先與欄位名稱結合起來, 才能看到重要性與欄位名稱的對照表\n",
    "    feats = pd.Series(data=estimator.feature_importances_, index=x.columns)\n",
    "    return feats.sort_values(ascending=False)\n",
    "\n",
    "#test\n",
    "feature, target = datasets.make_regression(n_samples=100, n_features=5)\n",
    "get_feature_importance(pd.DataFrame(feature,columns=[\"f1\",\"f2\",\"f3\",\"f4\",\"f5\"]), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評估指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, datasets\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#回歸問題 \n",
    "mae = metrics.mean_absolute_error(prediction, y) # 使用 MAE 評估\n",
    "mse = metrics.mean_squared_error(prediction, y) # 使用 MSE 評估\n",
    "r_square = metrics.r2_score(prediction, y) # 使用 r-square 評估\n",
    "\n",
    "#分類問題 AUC F1-Score (Precision, Recall)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "f1 = metrics.f1_score(y_test, y_pred_binarized) # 使用 F1-Score 評估\n",
    "precision = metrics.precision_score(y_test, y_pred_binarized) # 使用 Precision 評估\n",
    "recall  = metrics.recall_score(y_test, y_pred_binarized) # 使用 recall 評估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking\n",
    "http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/#example-3-stacked-cv-classification-and-gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.classifier import StackingCVClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing models\n",
    "def StackedCVClassification(X,y):\n",
    "    clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "    clf2 = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "    clf3 = GaussianNB()\n",
    "    lr = LogisticRegression()\n",
    "    sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                                #use_probas=True,\n",
    "                                meta_classifier=lr,\n",
    "                                random_state=42)\n",
    "    params = {'kneighborsclassifier__n_neighbors': [1, 5],\n",
    "              'randomforestclassifier__n_estimators': [10, 50],\n",
    "              'meta_classifier__C': [0.1, 10.0]}\n",
    "    grid = GridSearchCV(estimator=sclf, \n",
    "                        param_grid=params, \n",
    "                        cv=5,\n",
    "                        refit=True)\n",
    "    grid.fit(X, y)\n",
    "    cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "    for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "        print(\"%0.3f +/- %0.2f %r\"\n",
    "              % (grid.cv_results_[cv_keys[0]][r],\n",
    "                 grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "                 grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "    print('Best parameters: %s' % grid.best_params_)\n",
    "    print('Accuracy: %.2f' % grid.best_score_)\n",
    "    return ({\"best parameters\":grid.best_params_,\"accuracy\":grid.best_score_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_val_score(model_list,label_list,X,y):\n",
    "    d = {}\n",
    "    for clf, label in zip(model_list, label_list):\n",
    "        scores = model_selection.cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "              % (scores.mean(), scores.std(), label))\n",
    "        d[label] = scores.mean()\n",
    "    return d\n",
    "\n",
    "#test\n",
    "clf1 = KNeighborsClassifier(n_neighbors=10)\n",
    "clf2 = GaussianNB()\n",
    "get_cross_val_score([clf1,clf2],[\"knn\",\"gau\"],X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
